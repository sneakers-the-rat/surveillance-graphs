### Knowledge Graphs: Panoptica

In 2010 Google acquired Metaweb and its publicly-edited Semantic Web database Freebase, and in 2012 repackaged it and the ideas of Linked Data as what it called a **Knowledge Graph** --- the third era of the Semantic Web {% cite singhalIntroducingKnowledgeGraph2012 iainFreebaseDeadLong2016 %}. Freebase only made up part of it, and the full extent of Google's Knowledge Graph are unknown, but its most visible impact are the factboxes that present structured information about the subjects of searches - like biographical information in a search for a person - or the different widgets for contextual interaction - like being able to make a restaurant reservation from the serach page {% cite noyIndustryscaleKnowledgeGraphs2019 %}. Knowledge Graphs still share the same underlying structure --- triplet graphs with ontologies --- even if they occupy a broader space of implementations and technologies. What differs is the context and intended use: the "worldview" of the knowledge graph.

Beyond the obvious product-level features it supports, Google's acquisition of Freebase and the structure of its Knowledge Graph represent at least two deeper shifts in the trajectory of the Semantic Web and the broader internet: the privatization of technologies with initially liberatory aspirations, and an early template of the sprawling, surveillance-driven information conglomerate we know and love today. 

Like the radical nature of linking on the web, it's difficult to remember that the web as surveillance apparatus thinly veiled as the five or so remaining websites was not inevitable. The pre-dotcom bust internet of the 90's and early 2000's was far from the commercialized wasteland we know today. Ed Horowitz, CEO of Viacom explained in 1996: "The Internet has yet to fulfill its promise of commercial success. Why? Because there is no business model" {% cite tarnoffInternetPeopleFight2022 %}. Google's AdWords being a defining moment in the development of surveillance capitalism is a story already told {% cite zuboffAgeSurveillanceCapitalism2019 %}: taking advantage of the need for search generated by the disorganization of the web, AdWords turned personal search data into a profit vector by selling targeted space in the results.

The significance of the relationship between search, the semantic web, and what became knowledge graphs is less widely appreciated. The semantic web was initially an alternative to monolithic search engine platforms - or, more generally, to platforms in general {% cite berners-leeSociallyAwareCloud2009 %}. It imagined the use of triplet links and shared ontologies at a protocol level as a way of organizing the information on the web into a richly explorable space: rather than needing to rely on a search bar, one could traverse a structured graph of information {% cite berners-leeLinkedData2006 berners-leeGoalsHumanDataInterface2010 %} to find what one needed without mediation by a third party.

Instead, the form of of the semantic web that emerged as "Knowledge Graphs" flipped the vision of a free and evolving internet on its head. The mutation from "Linked Open Data" {% cite berners-leeLinkedData2006 %} to "Knowledge Graphs" is a shift in meaning from a public and densely linked web of information from many sources to a proprietary information store used to power derivative platforms and services. The shift isn't quite so simple as a "closure" of a formerly open resource --- we'll return to the complex role of openness in a moment. It is closer to an *en*closure, a *domestication* of the dream of the Semantic Web. A dream of a mutating, pluralistic space of communication, where we were able to own and change and create the information that structures our digital lives was reduced to a ring of platforms that give us precisely as much agency as is needed to keep us content in our captivity. Links that had all the expressive power of utterances, questions, hints, slander, and lies were reduced to mere facts. We were recast from our role as *people* creating a digital world to *consumers* of subscriptions and services. The artifacts that we create for and with and between each other as the substance of our lives online were yoked to the acquisitive gaze of the knowledge graph as *content* to be mined. We vulgar commoners, we data subjects, are not allowed to touch the graph --- even if it is built from our disembodied bits.




- The change in character is one of 'public information present on the web in the same medium that we use it in, I have tools to be able to directly interact with and understand the data, maybe by way of some automated reasoning agent that I control, but whatevers. -> something where corporations sit on their knowledge graph as *the thing* that they actually are as a business - their structured collection of informatino, the ability to collect and relate adn link it together and repackage it in improbable ways s.t. you always have some new information product to 

---

**THIS SECTION: Knowledge graphs as the corporatization of semantic web, culmination of the platformatization logic. cut to next section with a nod to the development of schema.org, why would organizations like this share data/given the focus on proprietariness, what is in it for them with seemingly open standards that might enable others?**

--

**Move this probably up before switching to talking about public and private?**
The competition between explicitly structuring the web and searching through it, and the role of Google specifically is not an incidental example among many, but instrumental to the development of the web as we know it (see Ben Tarnoff's excellent "Internet for the People" for a fuller account {% cite tarnoffInternetPeopleFight2022 %}). 

What do knowledge graphs give us that the older platform models didn't? the ability to link huge amounts of heterogeneous data, which dovetails with the emergence of the platform -> surveillance model

- Also schema.org starting in 2012 - exemplary of how 'open' efforts lead ultimately to greater dominance. 

- and so that transitions to the question at hand: the turn from strictly private corporate knowledge graphs to ones that can be broadly interoperable and extend to many more domains of life... it mirrors the way that "openness" via schema.org allowed them to consolidate a whole set of processes... so why might we care about government knowledge graphs...

This gives clarity to what exactly is an information business, what is 'good' for it - which kinds of openness are good and which are bad. because you want to be able to be able to maximize interfacial contact with indivudual people - sell ads, gather information - 
the interoperability of a bunch of knowledge graphs is good. you imagine your competitors just some other graph you might want to acquire some day. 
Through the alchemy of informational capitalism, you want to be able to rent and loan your graph out in pieces to competitors that aren't competing with you on a particular domain so that they might fight your other competitors on a different domain. 
it's like ultracapitalism where the capital is just infinitely fungible, but it's these graphs + compute!!! 
interoperability is not a threat because ultimately it's designed around a "graph + compute" anyway, so even if you could get your hands on the graph, you wouldn't be able to use it.


- Use in industry
- Differentiation from prior models of cloud computing and storage
- Why in particular were they adopted by google et al?
- Google's KG in particular:
	- {% cite juelvangEthicsGoogleKnowledge2013 %} - since its creation, people have been questioning the role of google as arbiter or all knowledge. In fact this really freaking pissed off wikipedia and is sort of indicative of the general pillaging of the commons that this kind of business model represent
- Other companies KGs {% cite noyIndustryscaleKnowledgeGraphs2019 %}
	- Microsoft:
		- Bing
		- Academic Graph
		- LinkedIn Graph
	- Facebook: {% cite weaverFacebookLinkedData2013 %}
- Natural counterpart to sprawling surveillance
	- This is exactly why they will be so powerful for our kind of generalized digital infrastructure we want to build: the corporate platforms have identified a tool that can be used to run the world's information. 
	- Eg relx. lots of information acquired over time from a lot of different locations, needs to be able to be reduced to some unified system, and graphs work at the level of propositions and assertions that can then be traversed and resolved. 
	- You also end up having a lot of multidomain data that could refer to the same entity, but in ways that were unanticipated by the initial schema for the object
	- unlike traditional relational databases, this is no problem for a graph. 
	- This also can work in a common interface: you get really dramatically different kinds of information for different kinds of objects, including different kinds of actions that can be taken, but those can be represented in a common format on a graph. 
	- Inference: you can then make logical inferences based on the networked information, this is a natural thing to want to do for search engines, as you are able to "fill in" information that isn't explicitly encoded in the database. Inference also is coproductive with the evolution into chatbots - if you provide some information about some flight you want to take, then the graph can know what information hasn't beeen provided in a complex concept. 

- What makes KGs special:
	- Explicit algo + KG model - entity oriented search: {% cite balogEntityOrientedSearch2018 %} 
	- KGs are best for heterogeneous data: {% cite ceravoloBigDataSemantics2018 %} and specifically in the business case: {% cite chaudhriKnowledgeGraphsIntroduction2022 %}
	- Specific role of standards efforts like Schema.org - where openness is strategically used in order to 


> While Palantir may claim otherwise, we believe there is enough evidence in these patents to suggest that Palantir has an internal knowledge base or knowledge graph for labeling entities in the world, along with their attributes and relationships, and that these occluded resources are not fully released to users, but that users are subject to them in using the products. {% cite iliadisSeerSeenSurveying2022 %}

- KGs are the dominant mode of integrating heterogeneous data: {% cite sequedaDesigningBuildingEnterprise2021 azziniAdvancesDataManagement2021 allemangMergingDataGraphs2022 %}

- Yes, wikidata exists, but it's extremely carefully managed with the intention of creating "facts" that don't embarass google {% cite chahOKGoogleWhat2018 %}
