### NSF: Open Knowledge Network

While the NIH builds a set of universal knowledge graphs for biomedical information, the NSF is building them for everything else. Its Open Knowledge Network (OKN) project intends to "provide an essential public-data infrastructure for enabling an AI-driven future." {% cite baruOpenKnowledgeNetwork2022 %} OKN is in an earlier stage of development than the Translator, so this section is less focused on the details of individual projects and more to argue the pattern of public/private knowledge graphs is an emerging consensus.

Compared to the Translator, the OKN pulls punches for neither its utopian promises nor obvious risks. Some sections of its [roadmap](https://web.archive.org/web/20221028095757/https://nsf-gov-resources.nsf.gov/2022-09/OKN%20Roadmap%20-%20Report_v03.pdf) are written in a style where each line shoots for the stars because even if some of them miss the result is a constellation of absolute bangers like "Harnessing the vast amounts of data generated in every sphere of life and transforming them into useful, actionable information and knowledge is crucial to the efficient functioning of a modern society[^whoomp]" {% cite baruOpenKnowledgeNetwork2022 %}. The project was initially proposed in 2017, went through two [cohorts](https://beta.nsf.gov/funding/initiatives/convergence-accelerator/portfolio) of projects within the [NSF Convergence Accelerator](https://beta.nsf.gov/funding/initiatives/convergence-accelerator/portfolio) in 2019 and 2020[^NSFconvergence], and [invited a broader submission](https://www.nsf.gov/pubs/2022/nsf22017/nsf22017.jsp) of proposals in November 2021 {% cite nationalsciencefoundationNSF22017Dear2021 %}. The roadmap comes at the end of a series of workshops in 2022 intended to scope and outline the OKN, so there is still very little public evidence of its progress to evaluate[^spoke].

Its domain is much broader than the Translator, and is unmistakeably bound up in both the United States Federal Government's military and political interests in Artificial Intelligence {% cite nationalsecuritycommissiononartificialintelligenceFinalReport2021 %} and the information economy's interests in making a universal space where all information can be bought and sold with minimal friction {% cite bigdatainteragencyworkinggroupOpenKnowledgeNetwork2018 %}. Where the Translator has the near-inevitable risk of being captured by information conglomerates, through the euphemism of "public private partnership" the OKN makes clear it was already captured at inception: the team behind the SPOKE biomedical knowledge network immediately spun off a for-profit startup to [sell the graph as a cloud service](https://www.matebioservices.com/spoke-cloud) {% cite matebioservicesinc.SPOKECloud2021 %}, abandoning further UX development of its [publicly accessible demo](https://spoke.rbvi.ucsf.edu/).

Without mincing words, the OKN intends to make a Universal Knowledge Graph of Everything. They check all the boxes[^pattern]: a) make authoritative schemas for everything, b) link them all together, c) ingest data from as many sources as possible at whatever quality available, d) integrate private with public data e) put it all in the cloud! (p. 18-19 "Creating an OKN" {% cite bigdatainteragencyworkinggroupOpenKnowledgeNetwork2018 %}). 

They OKN describes its work using a vocabulary of "vertical" "horizontal," where "vertical" applications refer to specific uses or domains like energy or health data, and "horizontal" themes like technologies and governance are shared across all domains. The work of the OKN is organized around specific use cases either within a "vertical" topic or a specific "horizontal" theme with the intent of later building them together into a shared infrastructure. The collection of "vertical" topics identified in the 2022 roadmap hint at the effectively unbounded scope of the OKN: accelerated capitalism via supply chain logistics, more tightly integrated weapons development, a handful of climate change projects, an omniscient financial system, and so on. Each imagines the primary problem in a given domain not as structural exploitation or injustice, but a lack of data[^systemsengineers].

A collection of "vertical" topical working groups in the 2022 roadmap centered on an algorithmic justice system are illustrative: An **Integrated Justice Platform** group describes how greater surveillance across every contact people have with the US Justice System is necessary to decrease bias. The group outlines a wish list of data sources they would integrate - arrest and booking, jail, trial, prosecution, and the rest. A **Decarceration** group[^boozallen] describes extending that surveillance through to the rest of incarcerated people's lives after they are released - rehab, parole, foster care, shelters, public services, etc. A **Homelessness** group intends to track unhoused people in order to match them to available resources. A **Decision Support for Government**[^smartcity] group describes bundling up these and other data sources into platforms for making "data driven decisions" on topics including crime and policing.

On their own, each of these groups describes noble goals: decreasing bias in the justice system, providing resources to formerly incarcerated or unhoused people, making government decisions more efficient. Taken together, however, the projects describe a panoptical surveillance system that wouldn't even need to be reconfigured to be used for algorithmically-enhanced oppression. I doubt any of the researchers in these groups intend for their work to be used for state violence, but *Palantir doesn't care what academics intended their tools to be used for[^palantirexternaldata].* 

The motivations behind integrating government data sources and automating public benefit delivery cannot overcome the context of systemic oppression they are embedded within. Group H, the "Homelessness OKN" group, takes particular effort[^sprint] to focus on the needs of the unhoused and address the potential risks of "track[ing] homelessness in real time, [and] identify[ing] available homelessness programs and services," but misses the already-real harms of similar prior efforts. Virginia Eubanks describes how Los Angeles County's Coordinated Entry System --- a program very much like that described by group H, intended to match unhoused people with housing supply by integrating previously siloed data systems --- operates as a sophisticated mechanism of control and punishment: 

> For Gary Boatwright and tens of thousands of others who have not been matched with any services, coordinated entry seems to collect increasingly sensitive, intrusive data to track their movements and behavior, but doesn’t offer anything in return. [...] Moreover, the pattern of increased data collection, sharing, and surveillance reinforces the criminalization of the unhoused, if only because **so many of the basic conditions of being homeless are also officially crimes.** [...] The tickets turn into warrants, and then law enforcement has further reason to search the databases to find “fugitives.” Thus, **data collection, storage, and sharing in homeless service programs are often starting points in a process that criminalizes the poor.** [...]
> 
> Further integrating programs aimed at providing economic security and those focused on crime control threatens to turn routine survival strategies of those living in extreme poverty into crimes. **The constant data collection from a vast array of high-tech tools wielded by homeless services, business improvement districts, and law enforcement create what Skid Row residents perceive as a net of constraint that influences their every decision.** Daily, they feel encouraged to self-deport or self-imprison. Those living outdoors in encampments feel pressured to constantly be on the move. Those housed in SROs or permanent supportive housing feel equally intense pressure to stay inside and out of the public eye. [...] **Coordinated entry is not just a system for managing information or matching demand to supply. It is a surveillance system for sorting and criminalizing the poor.** {% cite eubanksAutomatingInequalityHow2019 %}

It is impossible to consider integrated data in government without confronting the reality of algorithmic policing. Under its Strategic Plan goal of "Realiz[ing] Tomorrow's Government Today" Los Angeles County has already been integrating its information systems, including creating a unified system of law enforcement and other public service data "to identify super utilizers of justice and health system resources"[^cfive] {% cite chiefexecutiveofficecountyoflosangelesStrategicPlanGoal2022 farahaniLinkingPublicSafety2016 %}. Many police departments --- including the LAPD --- already have access to the kind of linked data ecosystems described by the OKN by renting them from private data brokers like Palantir {% cite braynePredictSurveilData2020 lamdanDefundPoliceDefund2020 %}. These data infrastructures facilitate the well-described feedback loop of predictive policing, where areas already subject to historical economic and racist violence are classified as "high-crime areas," more police are concentrated there, in turn causing them to measure or create more crime[^acab] {% cite braynePredictSurveilData2020 guarigliaTechnologyCanPredict2020  stoplapdspyingcoalitionRacialTerrorWhite2021 kathleenTargeted2020 stoplapdspyingcoalitionBulletHitsBody2018 stoplapdspyingcoalitionLetter28Professors2019 castelvecchiMathematiciansUrgeColleagues2020 %}. The reformist idea that more data will help us "police the police" is belied by the resolute history of more data allowing the police to innovate on information asymmetries to create new expressions of power {% cite hongPredictionExtractionDiscretion2022 stoplapdspyingcoalitionFUCKPOLICETRUST2020 %}.

The critical difference between prior infrastructures and those imagined by the OKN is that they are explicitly designed to be linked into a continuous network of data that enables the same kind of data-driven decisionmaking that drives predictive policing for *any* system. We should not be imagining the utterly mechanistic bureaucracy of *Kafka* here, but rather the deeply expressive and personal exercise of power of Terry Gilliam's *Brazil.* Widespread algorithmic governance doesn't necesarily look like a faceless bureaucracy where all decisions are made by a computer, existing algorithmic systems like predictive policing and the working conditions at Amazon warehouses retain the very human domain of *discretion* (see {% cite hongPredictionExtractionDiscretion2022 %}). The algorithms and seemingly open infrastructures of these two projects purport themselves as objective and egalitarian, but who they are built for, who gets to provides the inputs, and who decides which outputs matter make their reality very different. 

The very act of creating information infrastructures intended to algorithmically solve the world's problems is itself an expression of power-based discretion that diffuses energy that might be better spent elsewhere: rather than attempt to address the root cause, we can make a big show of *doing something* by diverting a large amount of resources and labor to gathering data and deriving "insights" about them. Beyond the specific risks of algorithmic policing and public benefits assessments, these projects presuppose an enlightened technocrat class as the principle agent of social good and design technologies accordingly. 

This is the properly *managerial* core of the positive vision of platform-driven mass surveillance: that a grand, unified graph of everything will allow the truth to emerge from the Big Data so that decisionmakers can divine what is best for the commoners who could not possibly understand the complexities of their health, environment, or social systems themselves. The conflict with the reality of the bureaucracies that might enact or support them temper those dreams, to the degree the prevailing corporate design logics of cloud-based infrastructure and what constitutes a fundable idea hadn't already[^utopiaofrules]. Rather than a smoothly flowing ocean of data, their fate is more likely to extend and elaborate the disjointed wash of [SaaS](https://en.wikipedia.org/wiki/Software_as_a_service) that defines institutional information systems. The petty tyrants will will gain new widgets on their dashboards rented from the information companies who absorbed the ontologies and harmonized data sources, automating their discretion under the guise of objectively meausurable fact. Meanwhile the new housing capacity might never arrive.

The prominent role of climate change among the topics identified by the OKN project is at once reassuring and depressing. Maybe what we need to solve climate change isn't data, it's to organize effective climate movements outside of the algorithmically disorienting information ecosystems designed to pump us full of engagement-maximizing rage-bait and transmute all movement building into influencer culture. Maybe what we need to address mass poverty isn't data, it's to dismantle the mechanisms of mass extraction that are increasingly powered by economies of surveillance. Maybe what we need to make the criminal justice system less racist isn't more data to feed into predictive policing algorithms, but to abolish the police.
