### NIH: The Biomedical Translator

<div class="note">
**Note:**

This section is reproduced from, focuses, and expands on "[Linked Data or Surveillance Capitalism?](https://jon-e.net/infrastructure/#linked-data-or-surveillance-capitalism)" from {% cite saundersDecentralizedInfrastructureNeuro2022 %}.
</div>

The NIH's Biomedical Data Translator[^translator] project was initially described in its 2016 Strategic Plan for Data Science as a means of translating between biomedical data formats:

> Through its Biomedical Data Translator program, the National Center for Advancing Translational Sciences (NCATS) is supporting research to develop ways to connect conventionally separated data types to one another to make them more useful for researchers and the public. {% cite nationalinstitutesofhealthNIHStrategicPlan2018 %}

The original [funding statement from 2016](https://web.archive.org/web/20210709100523/https://ncats.nih.gov/news/releases/2016/feasibility-assessment-translator) is similarly humble, and press releases [through 2017](https://web.archive.org/web/20210709171335/https://ncats.nih.gov/pubs/features/translator) also speak mostly in terms of querying the data -- though some ambition begins to creep in. By 2019, the vision for the project had shifted from *translating* between data types into the realm of heterogeneous linkages in some meta-level system for linking and *reasoning* over them. 

In their piece "Toward a Universal Biomedical Translator," then in a feasibility assessment phase, the members of the Translator Consortium assert that universal translation between biomedical data is impossible[^impossibledata]{% cite consortiumUniversalBiomedicalData2019 %}. The impossibility they saw was not that of conflicting political demands on the structure of organization (as per {% cite bowkerSortingThingsOut1999 %}), but of the sheer quantity of the data and vocabularies needed to describe them. The risk posed by a lack of a universal "language" was not being able to index all possible data, rather than inaccuracy or inequity[^babel].

Undaunted by their stated belief in the impossibility of a universalizing ontology, the Consortium created one in their [biolink](https://biolink.github.io/biolink-model/docs/) model[^biolinkpaper] {% cite bruskiewichBiolinkBiolinkmodel2021 unniBiolinkModelUniversal2022 %}. Biolink consists of a hierarchy of general[^generality] classes: eg. a [BiologicalEntity](https://biolink.github.io/biolink-model/docs/BiologicalEntity.html) like a [Gene](https://biolink.github.io/biolink-model/docs/Gene.html), or a [ChemicalEntity](https://biolink.github.io/biolink-model/docs/ChemicalEntity.html) like a [Drug](https://biolink.github.io/biolink-model/docs/Drug.html). Classes can then linked by any number of properties, or "Slots[^slots]." 

Biolink was designed to be a sort of "meta ontology," or a means of mapping different domain-specific biomedical ontologies onto a common vocabulary[^tooling]. As a meta-ontology, Biolink is targeted towards "meta-data." Rather than accommodating "raw data[^norawdata]," Biolink is expected to operate at the level of "knowledge," or "generally accepted, universal assertions derived from the accumulation of information" {% cite fechoProgressUniversalBiomedical2022 %}: this procedure [treats](https://biolink.github.io/biolink-model/docs/treats.html) that disease, this chemical interacts with that one, etc. 

The primary way Biolink is used within the Translator is to structure a [registry of database APIs](http://www.smart-api.info/registry), each called a "Knowledge Source." Knowledge Sources use Biolink to declare that they are able to provide assertions about a particular set of classes or slots, like [drugs that affect genetic expression](http://www.smart-api.info/ui/adf20dd6ff23dfe18e8e012bde686e31), which makes them part of the Translator's distributed [Knowledge Graph](http://www.smart-api.info/portal/translator/metakg). The Translator project, in this universalizing impulse, recapitulates some of the early beliefs of the Semantic Web updated with some of the techniques of Linked Data.

This structure strongly constrains who is intended to be able to contribute to the Translator: highly curated biomedical informatics platforms, rather than basic researchers or the public at large. [NIH RePORTER](https://reporter.nih.gov/search/DShVUhB_ZUq0X5UWFjy5WQ/projects?shared=true) shows a series of grants for small councils of experts to create domain-specific ontologies and Knowledge Sources. This, in turn, reflects deeper beliefs about the nature of information within the Translator ecosystem: "knowledge" is not a social, contextual, or dialogical phenomenon, but a "natural resource" that can be [mined](https://reporter.nih.gov/project-details/10548337) from information that is "out there." A scientific paper is a neutral carrier of a factual link between entities. The meaning of "translation," in some uses, has shifted from translating *between data formats*, to *"translating information into knowledge"* {% cite consortiumUniversalBiomedicalData2019 %}. This is, of course, the ideology of Big Data: "when heterogeneous networks are connected at a massive scale, new knowledge can be extracted as an emergent property of the network" {% cite morrisScalablePrecisionMedicine2023 %}.  The Translator seems to imagine its project as a refinery, converting crude data into Knowledge that can fuel platforms.

The platforms that the translator imagines are those where clinicians or researchers can pose plain language queries and have answers returned by some algorithmic "reasoning agent" that aggregates data from multiple Knowledge Providers and synthesizes a response {% cite unniBiolinkModelUniversal2022 renaissancecomputinginstituterenciBiomedicalDataTranslator2022 renaissancecomputinginstituterenciUseCasesShow2022 goelExplanationContainerCaseBased2021  hailuNIHfundedProjectAims2019 %}. We are not intended to look too closely at the data from Knowledge Providers, as it is likely to be incomplete or conflicting.

Several pilot experiments have demonstrated combining some aggregated patient records with the broader knowledge graph in order to eg. identify new risk markers for disease {% cite morrisScalablePrecisionMedicine2023 nelsonEmbeddingElectronicHealth2021 translatorconsortiumClinicalDataServices2020 nelsonIntegratingBiomedicalResearch2019 %}. These systems layer personal records underneath "general" biomedical information like drug interactions and biological processes and use the extended information from the graph to infer information both about the nature of the disease and the patient. [A platform](https://www.matebioservices.com/bridge) integrated with the UCSF electronic health record system that layers disaggregated clinical records under the general knowledge graph is already apparently in a state of mature development {% cite universityofcaliforniasanfranciscoBRIDGE %}. 

It is only with the inclusion of patient records into the knowledge graph that it becomes possible to use in a clinical setting: for even basic queries like "which drugs treat this disease" one has to be aware of patient qualities like allergies and comorbid conditions. To know how to treat the generic diagnosis of "gender dysphoria," one needs to know which gender the patient is experiencing dysphoria about. The logic of knowledge graph makes it not just hungry for *some* personal medical data, the promise is that more data **always** improves its results[^moredata]. 

Why might we be critical about the NIH funding a series of projects to unify biomedical and personal health data in some universalized, platformatized knowledge graph? In short: because it won't work as intended, its partially-working components will have immediately harmful results, and it will inevitably be captured by the surveillance industry.

First, as with any machine-learning based system, the algorithm can only reflect the implicit structure of its creation, including the beliefs and values of its architects {% cite birhaneValuesEncodedMachine2022 birhaneAlgorithmicInjusticeRelational2021 %}, its training data and accompanying bias {% cite birhaneMultimodalDatasetsMisogyny2021 %}, and so on. The "mass of data" approach ML tools lend themselves to, in this case, querying hundreds of independently operated databases, makes dissecting the provenance of every entry from every data provider effectively impossible. For example, one of the providers, [mydisease.info](https://mydisease.info) was more than happy to respond to a query for the outmoded definition of "transsexualism" as a disease {% cite ramTransphobiaEncodedExamination2021 %} along with a list of genes and variants that supposedly "cause" it - [see for yourself](https://web.archive.org/web/20230315040436/mydisease.info/v1/query?q=%22DOID%3A10919%22). At the time of the search, tracing the source of that entry first led to the disease ontology [DOID:1234](https://web.archive.org/web/20211007053446/https://www.ebi.ac.uk/ols/ontologies/doid/terms?iri=http%3A%2F%2Fpurl.obolibrary.org%2Fobo%2FDOID_1234), which has an [official IRI](http://purl.obolibrary.org/obo/doid.owl), but in this case was being served by a graph aggregator [Ontobee](http://www.ontobee.org/ontology/DOID?iri=http://purl.obolibrary.org/obo/DOID_1234) ([Archive Link](https://web.archive.org/web/20210923110103/http://www.ontobee.org/ontology/DOID?iri=http://purl.obolibrary.org/obo/DOID_1234)), which in turn listed this [unofficial GitHub repository](https://github.com/jannahastings/mental-functioning-ontology) **maintained by a single person** as its source[^ipredit]. This is, presumably, the fragility and inconsistency in input data that the machine learning layer is intended to putty over.

If the graph encodes being transgender as a disease, it is not farfetched to imagine the ranking system attempting to "cure" it. In a seemingly pre-release version of the translator's query engine, ARAX, it does just that: in [a query for entities with a `biolink:treats` link to gender dysphoria](https://web.archive.org/web/20220828011010/https://arax.rtx.ai/?r=e891e6e6-44fd-4684-9d36-f94e3e81b554)[^araxtrans], it ranks the standard therapeutics {% cite deutschOverviewFeminizingHormone2016 deutschOverviewMasculinizingHormone2016 %} Testosterone and Estradiol 6th and 10th of 11, respectively --- behind a recommendation for Lithium (4th) and Pimozide (5th) due to an automated text scrape of [two](https://pubmed.ncbi.nlm.nih.gov/2114800/) conversion therapy [papers](https://pubmed.ncbi.nlm.nih.gov/8839957/)[^dateextract]. Queries to ARAX for [treatments for gender identity disorder](https://web.archive.org/web/20220828011112/https://arax.ncats.io/?r=52703) helpfully yielded "zinc" and "water," offering a paper from the translator group that describes automated drug recommendation as the only provenance {% cite womackLeveragingDistributedBiomedical2019 %}. A query for treatments for `DOID:1233` "[transvestism](https://web.archive.org/web/20221207013845/https://arax.rtx.ai/?r=81249a42-b300-4dcf-94c9-7a9fe2f78237)" was predictably troubling, again prescribing conversion therapy from [automated](https://pubmed.ncbi.nlm.nih.gov/3271001/) [scrapes](https://pubmed.ncbi.nlm.nih.gov/10493039/) of [outdated](https://pubmed.ncbi.nlm.nih.gov/8591978/) and [harmful](https://pubmed.ncbi.nlm.nih.gov/1176977/) [research](https://pubmed.ncbi.nlm.nih.gov/14288075/). The [ROBOKOP](https://robokop.renci.org/answer) {% cite bizonROBOKOPKGKGB2019 %} query engine behaved similarly, answering [a query for genes associated with]({{ "/data/ROBOKOP_message.json" | relative_url }}) gender dysphoria with exclusively trivial or incorrect responses[^robokopdidntwork].

It is critically important to understand that with an algorithmic, graph-based precision medicine system like this **harm can occur even without intended malice.** The power of the graph model for precision medicine is precisely its ability to make use of the extended structure of the graph[^flows]. The "value added" by the personalized biomedical graph is being able to incorporate the patient's personal information like genetics, environment, and comorbidities into diagnosis and treatment. So, harmful information embedded within a graph --- like transness being a disease in search of a cure --- means the system either a) incorporates that harm into its outputs for seemingly unrelated queries or b) doesn't work. This simultaneously explodes and obscures the risk surface for medically marginalized people: the violence historically encoded in mainstream medical practices and ontologies (eg. {% cite ramTransphobiaEncodedExamination2021 ashleyMisuseGenderDysphoria2019 %}, among many), incorrectly encoded information like that from automated text mining, explicitly adversarial information injected into the graph through some crowdsourcing portal like [this one](https://collaboratory.semanticscience.org/) {% cite masstrichtu-idsKnowledgeCollaboratory2022 %}, and so on all presented as an ostensibly "neutral" informatics platform. Each of these sources of harm could influence both medical care and biomedical research in ways that *even a well-meaning clinician might not be able to recognize.*

The risk of harm is again multiplied by the potential for harmful outputs of a biomedical knowledge graph system to trickle through medical practice and re-enter as training data. The Consortium also describes the potential for ranking algorithms to be continuously updated based on usage or results in research or clinical practice[^reasoner-training] {% cite consortiumUniversalBiomedicalData2019 %}. Existing harm in medical practice, amplified by any induced by the Translator system, could then be re-encoded as implicit medical consensus in an opaque recommendation algorithm. There is, of course, no unique "loss function" to evaluate health. One belief system's vision of health is demonic pathology in another. Say an insurance company uses the clinical recommendations of some algorithm built off the Translator's graph to evaluate its coverage of medical procedures. This gives them license to lower their bottom line under cover of some seemingly objective but fundamentally unaccountable algorithm. There is no need for speculation: [Cigna already does this](https://www.propublica.org/article/cigna-pxdx-medical-health-insurance-rejection-claims) {% cite ruckerHowCignaSaves2023 %}. Could a collection of anti-abortion clinics giving one star to abortion in every case meaningfully influence whether abortion is prescribed or covered? Why not? Who moderates the graph?

The centralized structure of the Translator's Knowledge Providers and query engines make a small group of experts responsible for curating the entire structure of biomedical information. The curation process could be "crowdsourced" to allow affected communities to suggest improvements, but the platformatized nature of the Translator both concentrates decisionmaking power and diffuses responsibility across a string of platform holders. Who is supposed to fix incorrect or harmful query responses? Is it the responsibility of the potentially dozens of Knowledge Providers, the swarm of reasoning agents, or the frontend wrapper you pay a monthly subscription for? It is the platformatized nature of the Translator itself that creates the need for centralized moderation in the first place. The design of the Translator to evolve into a series of "user-" or customer-facing platforms that aspire to universality binds it to all the regulatory burden any biomedical technology bears. The cost of moderation will of course be enormous, placing a fundamental constraint on its lifespan as a publicly funded project --- and a strong incentive towards co-option by the information conglomerates capable of paying it[^section206].

These problems hint at the likely fate of the Translator project. Rather than integrating into the daily practice of researchers, the centralized process of creating Knowledge Providers can only be maintained for as long as the grant funding for the Translator project lasts. When [queried](https://arax.rtx.ai) at the time of writing, of the 25 knowledge providers that were responsive to information about "Anything that is related to the common cold," 22 were unresponsive or timed out. 

How the Translator is intended to work by its architects is almost irrelevant compared to the question of what happens to it *after the project ends.* Linking biomedical and patient data in a single platform is a natural route towards a multisided market where records management apps are sold to patients, treatment recommendation systems are sold to clinicians, research tools and advertising opportunities are sold to pharmaceutical companies, risk metrics are sold to insurance companies, and so on. The contours of this market are already clear.

As a non-exhaustive set of examples:

- I have already described **RELX**'s interest in personal biomedical data. Their 2022 Annual Report {% cite relxAnnualReport20222023 %} is the first year where they explicitly describe their entrance into the patient data market[^RELXmedicaldata]. RELX is a particularly worrying example because of their established roles among academics, governmental entities, medical systems, and insurance providers. 
- **Amazon** already has a broad home surveillance portfolio {% cite bridgesAmazonRingLargest2021 %}, and has been aggressively expanding into health technology {% cite AWSAnnouncesAWS2021 %} and even literally providing [health care](https://amazon.care/) {% cite fingasAmazonOfficiallyBecomes2023 lermanAmazonBuiltIts2021 %}, which could be particularly dangerous with the uploading of all scientific and medical data onto AWS with entirely unenforceable promises of data privacy through NIH's STRIDES program {% cite quinnYouCanTrust2021 %}. 
- **Google** already includes medical conditions in its surveillance-backed advertising profiles {% cite krashinskyGoogleBrokeCanada2014 bharatGeneratingUserInformation2005 %}, and is edging its way into wearable health data with eg. its acquisition of FitBit {% cite bourreauGoogleFitbitWill2020 %}. It also already has a system, Med-PALM, for biomedical question answering based on large language models {% cite piferGooglePlansBoost2023 matiasOurLatestHealth2023 singhalLargeLanguageModels2022 %}. Search is a primary entrypoint for many people seeking health information, and Google presumably would be more than happy to merge that data with a generalized biomedical knowledge graph.
- **Apple** already has a matured Health ecosystem of apps and services for both patients, clinicians, and researchers {% cite appleEmpoweringPeopleLive2022 appleHealthcare %} and has a similar exposure to relevant data and control of platforms (iOS, watchOS) to make use of it, though they have marketed themselves in the surveillance space as a defender of privacy.
- Of course **Microsoft** {% cite sinhaOverviewMicrosoftAcademic2015 %} and **IBM** {% cite chenIBMWatsonHow2016 %} are also in play.

The design of the Translator project reflects the prevailing logic of the surveillance economy as powered by knowledge graphs, and is poised to be swallowed up by it. Rather than a means for us to collectively make sense together, it imagines a cloud-driven system where a small group of experts wave a wand of unknowable algorithms over a bulging plastic trash bag of data to pull out the Magic Knowledge Rabbit. The noble intention of making a generalized biomedical knowledge graph for the public good is unlikely to be realized. In the process, though, the NIH will have funded facilitating technologies and standards for the merger of personal electronic health records with the broader landscape of biomedical data. Academics will have new vectors by which they become unwitting or unwilling collaborators[^techtransfer] with surveillance and data brokers, lending what credibility they have left to a landscape of buggy black boxes of biopolitical control. And, most importantly, vulnerable populations will have dozens of new ways to be marginalized by the techno-political medical establishment.


