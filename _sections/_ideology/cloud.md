## The Cloud Orthodoxy



not a complete definition, but describing some basic traits. not all traits are always true, but they fit together into a means of understanding digital infrastructures - a means of establishing values 

- read and cite:
	- {% cite allhutterWorkingOntologistsHighQuality2019 %}

Why on *earth* would we want our insurance provider to be able to adjust their premiums based on our private medical information, even if it is "de-identified"

The problem of belief: what should these things do? present us instantly with results? or should they be part of a messy dialectic of information where the graph itself is the outcome? The cloud orthodoxy suggests the former!

- Need to articulate the components of the cloud orthodoxy mindset
	- Automated reasoning
	- More data is better
	- 'data' as a projection of 'information' is a commodity, inert, factual, external.
	- Neutral reflection of underlying facts, only conditioning factor is 'confidence', but no criticism of schema
	- End goal is productized services: eg. the fantasy of the google researcher in 2018 at the end of entity oriented search
	- Convenience
	- Performance
	- Assumes that we are all subjects of surveillance, that the data is "out there" to be mined, and its heterogeneity is an inconvenience or technical problem.
	- There is "one" of something - there is one index that refers to the concept of a man, or a given person, etc. rather than many contextual representations of that thing.
		- the poltics of ontologies are neatly illustrated by the fact that "a woman is a woman" means precisely the opposite thing w.r.t trans woman to transmisics as compared to normal people.
	- It doesn't have to work! as long as it seems like it does
	- Rather than building tools for people that they might use to actually integrate the system in their work or lives, but instead some means of scraping it afterwards (eg. SCALES), so who is this actually for? the people studying people doing work, or for the people doing the work? When things are intended for the people actually doing the work, they are invariably platforms that provide just enough functionality to keep people using them while surveilling them as the main purpose.
	- we are interchangeable consumers, we are not expected to "have anything" or "come with anything" - we are customers of some web service. The notion of **agency** is never afforded to people: **agents** are computational, and specifically on a computer than you don't own. You can tell a web agent to do something for you, but you yourself do not have agentic behavior on ther web.
	- the expectation that we shouldn't have to organize something, that we should be able to buy it.
	- that we should be able to complain to the manager, because we are the customer
	- in some ways most of this is pinned in place by the ideology of capitalism, if youh ave a backdrop of some companies needing to take some action, they abstract away the social relationship of labor into a product for you, which you can then rent. 
	- trust via gatekeeping: you can trust us because we limit the power within the system carefully, as opposed to eg. soft security
		- trust in a corporate context is having someone to sue, but the same conditions of trust don't need to apply in all contexts.

- YOU ONLY NEED TO DO THIS SCALE OF AUTOMATED EXTRACTION IF YOU PRESUPPOSE A UNIVERSE OF A FEW MASSIVE PLATFORMS OWNING EVERYTHING IN THE FIRST PLACE re: amazon product graph example in {% cite chaudhriKnowledgeGraphsIntroduction2022 %}

--- 


- The argument that the next phase of everything is chatbots and 


The merger of AI shit and knowledge graph shit

So if web 2.0 was about the platformatization of the web, what is up next? In the same way that information conglomerates successfully harnessed open source for profit, now can we effectively gamify the entirety of knowledge generation process? can we put ppl inside of information curation chambers when they search?

"Explainable AI" is gonna come from knowledge graphs yo

Broad principles
- Strategic use of "openness" when it facilitates greater market control and to prevent someone else from capturing a particular element of the technology.	
	- Same thing as with the DOI: the linking agreements were killing us! Get some barrier to commerce out of the way (ontology discontinuity) so that the commerce can intensify, not so that it can abate

> Peter Mika: A natural next step for Knowledge Graphs is to extend beyond the boundaries of organisations, connecting data assets of companies along business value chains. This process is still at an early stage, and there is a need for trade associations or industry-specific standards organisations to step in, especially when it comes to developing shared entity identifier schemes. {% cite panExploitingLinkedData2017 %}