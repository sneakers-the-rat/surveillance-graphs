## Vulgar Linked Data

> "The popular vernaculars are vast speech-jungles, in which old forms are decaying and new ones continually springing into life; and this fermentation results in the creation of numberless new terms, which come to birth and live and die in tropical profusion. They are formed in living response to the needs of the moment; the greater number of them hardly survive the occasion that brought them forth; but others, on account of their expressive power and their usefulness, establish themselves, spread from district to district. [...]
>
> For human speech is after all a democratic product, the creation, not of scholars and grammarians, but of unschooled and unlettered people. Scholars and men of education may cultivate and enrich it, and make it flower into all the beauty of a literary language; but its rarest blooms are grafted on a wild stock, and its roots are deep-buries in the common soil. From that soil it must still draw its sap and nourishment, if it is not to perish, as the other standard languages of the past have perished, when, in the course of their history, they have been separated and cut off from the popular vernacular --- from that vulgar speech which has ultimately replaced their outworn and archaic forms." 
>
> --- L.P. Smith (1925) *"Words and Idioms"* {% cite smithWordsIdiomsStudies1925 %}

> Control, control for who? for what?<br>I'm no robot, they can get fucked.
>
> --- Black Flag (1981) *"No More"*

Is it still possible to imagine a different world than the one the information conglomerates have planned for us? Can we imagine a properly *human* information infrastructure?

We can start by identifying the harms of the world as it exists to understand why a new world is needed, as I have attempted some small part of in this piece. Harm, in this case, is not some speculative future of superintelligent sentient AI, but elaboration of ongoing harms of the surveillance and platform economies. 

Building a better informational world is not a matter of choosing a different set of technologies --- I argue that in this case some of the masters tools can help us rebuild his house. At the same time we can't overcorrect in our focus on social problems and dismiss technology as a strategy, a tool, and a manifestation of values, belief, and labor. We must have an answer to the well meaning liberal that mistakes the dynamics of surveillance capitalism or their role in it: that understands that these knowledge graphs are not truly universal, that the LLMs are not sentient, but embraces their logic because they're so *useful.* We have to understand why simply building open source LLMs or nonprofit linked data platforms is not a liberatory strategy. We have to have the courage to face the underlying structural informational problems in our organizations at all scales --- that instead of reimaginging how we work and communicate, we can't simply strap "AI" onto our problems and expect to solve them. We have to recognize that sidestepping the hard socio-technological problems of information organization is a continuation of, not solution to the patterns that cause them.

At the same time, we can't dismiss those needs. How could we possibly tell someone with vision impairments not to use "AI" tools for summarizing images, or someone with motor or speech impairments not to use LLMs as a communication aid? It is true that making better use of biomedical data could lead to better treatments. Indecipherable government bureaucracy due to ancient data infrastructure is an informational injustice. So simple abstinence or resistance to universalizing knowledge graphs and LLMs is also not an effective or just strategy, especially if the alternative is a conservative embrace of the existing cloud platform regime whose logic spawned them.

The constant partial satisfaction and construction of new needs, *the hollow middle* at the center of every cloud platform, is a powerful opening. The structure of contemporary platforms always pose a fundamental lack:[^platformstudies] as a service, some functionality must always be withheld to create a walled garden or nurture dependence. Even platforms without an intended profit motive have their own "platform logic" --- constraining their use to only exactly what the developers intended it to be used for. For a project intended to organize information, why is it difficult for me to find the different components of the Translator project? Since its creators imagined "users" interacting only with the frontends of its platforms, little emphasis was placed on the discoverability of the whole system, and, critically, there is no way for me to contribute something like that and have it be visible by . This is true of all the ways large and small that platforms are mismatched with our expectations and needs --- even though we subscribe to 15 or 20 different platforms, why is it that we always need to find yet another to do something even slightly outside the finite imagination of their developers?[^listicles]

Another set of openings come from the problems cloud platforms pose for themselves that are flatly ridiculous when described plainly. *Why on earth* do I have to route my file through some cloud datacenter thousands of miles away to send it several inches between my phone and computer? *Why on earth* should I need a near-flawless, high-bandwidth internet connection to *edit a plain text document?* *Why on earth* do I have to rely on an effectively unregulated and hostile intermediary like Facebook or Twitter to communicate with my family and friends, or even to *merely exist online?* *Why* should I have to waste 500mL of potable water to check the weather? {% cite liMakingAILess2023 %}? *Why* is my *car* spying on me so some company I have never heard of can sell my data to an insurance provider? *Why* is it possible for a hospital system to volunteer my personal medical information without IRB approval {% cite nelsonIntegratingBiomedicalResearch2019 %}? Why is the best we can do to frame that question as a matter of consent, *why is it possible for a platform to create and store and manipulate my personal information at all? {% cite hongControlCreepWhen2021 %}* You only have to engineer the kinds of systems capable of automatically[^humanlabor] extracting all information on the web *if you imagine the only possible system as one that universally indexes all information as one of a few hegemonic platforms.* Why do we have to settle for systems that purposely limit our expectations to what the platform can provide as a "best guess?[^searchenginesnotinevitable]" Why do we have to work around the dark patterns designed to corral our behavior rather than building digital worlds that meet our needs for communication and community?

How did we come to imagine ourselves as so powerless?

Clearly, we need a change in *belief* to effectively challenge the deeply entrenched cloud-surveillance-platform archipelago. We need to unlearn what we have been taught to want, what we believe information technologies should do, and how they are supposed to work. We need to rethink our role in information technology, to move beyond the learned helplessness of the platform consumer and the petty tyranny of the platform operator. We need to reorganize our expectations of agency, beyond the division of labor that gives the power of final say over informational systems in the hands of a cadre of experts that the rest of us just make the best of. We don't have time to argue about whether we *can* build a better world[^crimethinc], to list all the many ways we are hemmed in by infrastructure and incentives, or to wait for another powerful entity with decidedly divergent interests like a government[^aiwar] to save us --- we need to believe we too can be powerful.

An attempt to define another "Correct" counter-belief system would be missing the point, but we can't ignore the importance of naming and articulating belief in opening the possibility for and aligning action[^crimethinc2]. Our old belief systems are getting musty. It has been an important rallying cry, but **"Openness" alone has failed as a liberatory strategy.** All we make and offer up to each other freely is stolen ten times over by those who have much grander visions of enclosure. Without a strategy to resist co-option, our openness puts tools in the hands of the powerful. This is also not a fight that can be won with technical or legal changes like [ethical source licenses](https://ethicalsource.dev/licenses/), though they are a useful idea. Drawing from a historiography of prior digital cultural movements like the semantic web, piracy, and the loosely-defined "fediverse[^amongothers]," I[^notjustme] argue that **vulgarity** opens up the space of belief for rethinking data infrastructures and attempt a rough definition.

---

**We** are the principle value of vulgar linked data. We don't wait for permission to be free, nor are we waiting on anyone else to save us. **Convenience is secondary to to agency. Social bonds are more valuable than uptime.** Our systems might stutter or crash sometimes, but we know who runs it because they are one of us. When we have a need, we make the tools to address it ourselves. We know nothing comes for free unless we make it so, and we are skeptical of "solutions" that drop from the sky, asking nothing of us, because they have a habit of making us into a product. We **cultivate abundance** instead of scarcity, and **cooperation** is the only magical solution we are aware of.

**We have no dreams of universality** or world domination, nor do we aspire to always make sense. We **linger in complexity** and relish in it. We are smart and sometimes brain is broken. We are capable and inept. We are complicated, we are **pluralistic and multiple.** We reject the colonial project of the Single True System, we have no teleology of seamless homogeneity. **We embrace heterogeneity** and ambiguity as the signifiers of *life.* We don't leave each other behind, and **if a system isn't accessible, it doesn't work.** The power of expression is more valuable than Correctness, if there is such a thing. **Meaning is intrinsically relational,** something that always exists *between* us, that we make ourselves. We weave webs of **translation** between local meanings, knowing that everything is understood as many senses to many people at the same time.

**Our infrastructures are social.** There is no class distinction between "developer" and "user." We resist concentrated power in favor of mutual empowerment. We don't seek to cultivate dependence in councils of elders or create new chokepoints of control. Anything worth making is a potential source of power, so **anything worth making is worth distributing governance of.** We don't assume the needs of others, but make tools so we can meet our own needs. **We don't make platforms, we make protocols** with rough consensus based on what works. We are autonomous, but neither isolated nor selfish. Our dream is not one of solipsism, glued to our feeder bar, being "fed" the pellets of our social reality. **We are radically responsible for one another,** and by organizing together we can provide services as mutual aid. Mutual empowerment means that **we are free to come and go as we please,** even if we might be missed. We have no love for venerated institutions and organize fluidly, making systems so we can merge and fork[^righttofork] code and ourselves freely {% cite bookchinNoteAffinityGroups1969 MeatballWikiRightToFork %}.

**Information is communication.** We communicate with each other to share our joy and pain and wisdom and the rest of the experiences of our life. **Our Data is like language** --- in vernacular formats and ontologies, propositions from a person rather than as a disembodied fact. We own our data in the same way that we are responsible for the things we say. Data created *about us* through systems like surveillance has all the importance of unsubstantiated rumour. **Openness as a concept dissolves when there is no enclosure.** We share publicly the things we intend to share publicly, though we might resist the scraping gaze of conglomerates that might seek to make our communication a product. We scope what we share privately to the people we intend to see it. **Communication requires consent,** and when we share our personal information we have the right to grant and withdraw that consent. **Communication is multivalent,** and academic prose sits comfortably next to shitposts. **No idea exists in isolation,** and when we adopt or remix or criticize what each other have made we can see the many threads that have led to any particular stitch in a larger quilt. The same systems that facilitate public communication can protect marginalized people or activists hunted by the state. **We keep each other safe.** We [EnlargeSpace](http://meatballwiki.org/wiki/EnlargeSpace) {% cite MeatballWikiEnlargeSpace %} rather than attempting to fit everyone into a universalizing system. 

We don't *fight* the powerful, we make the sources of their power *obsolete* by making our own world.
 
---

The information systems we need are [*vulgar*](https://www.etymonline.com/search?q=vulgar) {% cite harperVulgar %} in that they are of us, for us, and resist formalizing authority and global-logical coherence. We are revitalizing and extending the old notions of linked data, and particularly extending its "scruffy" tradition {% cite poirierTurnScruffyEthnographic2017 %} to drop the pretense of an eventually-unified ontological space in favor of one that explicitly values heterogeneity and vernacularism. 

I have written [at length](https://jon-e.net/infrastructure) about what vulgar linked data might look like in practice, but that work is of course always ongoing. In short, it is based around a new generation of **peer to peer** technologies[^realp2p] that are designed to be explicitly social, rather than homogenous like BitTorrent where a peer is only identified by their IP address. One instantiation of communication could use collections of triples akin to [linked data fragments](https://linkeddatafragments.org/concept/), or perhaps extend them to be quartets that explictly include an author. These triple collections could be manipulated by a number of familiar interfaces initially, like chatrooms, documents, threaded media like Mastodon and so on. It should facilitate social organization by allowing individual peers to federate with one another, agreeing to mirror subsets of each others data, potentially making use of larger and more fixed resources as well as low power consumer devices. The network can be made more efficient by content addressing each collection of triples, and can make use of encryption schemes like capability-based security to scope data to a specific set of recipients. The goal would be to make an evolving protocol that can represent some underlying information in arbitrary interfaces from scientific data through the mundanities of everyday communication like sharing photos or planning events.

In the short term this looks more like [mayfirst](https://mayfirst.coop/en/) or [co-op cloud](https://coopcloud.tech/) than traditional cloud systems, where people voluntarily cooperate to build infrastructure that isn't the faceless corporate technology that dominates computing currently. The fediverse is another ongoing experiment in collectively owned, interoperable systems, where individual groups like we at [neuromatch.social](https://neuromatch.social) organize and administer their own systems. Longer term we can start building these out to true peer to peer technologies that are a fundamental departure from client-server cloudlike models.

More important than the specific technological instantiation is a shift in what we *value* in technology and what we believe it should do. Rather than customers renting a handful of platforms, we can organize our own infrastructures for storage and computation to displace cloud platforms across multiple modalities. We can *counterbuild* the fill the space currently occupied by the cloud without replicating its 

We face a stark choice for our future. The Cloud is circling, will it eat us alive? Will we build a space of universalizing knowledge graphs that allow the seamless linking and trade of every element of our society, powering algorithmic systems from information organization through medical systems, governance, and policing. Will we continue to let information conglomerates farm us for our data and feed it back to us, reprocessed, as Content and Knowledge™? Will we be hooked by the lip by barbed convenience that promises us magic, but delivers us only greater surveillance, control, and dependence? Will our attempts at resistance only ever amount to a neverending treadmill of startups and publicly-funded projects that can't break from the gravitational pull of The Cloud Orthodoxy, retreading its worldview of asymmetrical power concentration, inevitably shuttered or bought as they fail to compete on the same territory as the information giants? 

Or will we build a better world?
