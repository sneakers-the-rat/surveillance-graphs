## Vulgar Linked Data

> "The popular vernaculars are vast speech-jungles, in which old forms are decaying and new ones continually springing into life; and this fermentation results in the creation of numberless new terms, which come to birth and live and die in tropical profusion. They are formed in living response to the needs of the moment; the greater number of them hardly survive the occasion that brought them forth; but others, on account of their expressive power and their usefulness, establish themselves, spread from district to district. [...]
>
> For human speech is after all a democratic product, the creation, not of scholars and grammarians, but of unschooled and unlettered people. Scholars and men of education may cultivate and enrich it, and make it flower into all the beauty of a literary language; but its rarest blooms are grafted on a wild stock, and its roots are deep-buries in the common soil. From that soil it must still draw its sap and nourishment, if it is not to perish, as the other standard languages of the past have perished, when, in the course of their history, they have been separated and cut off from the popular vernacular --- from that vulgar speech which has ultimately replaced their outworn and archaic forms." 
>
> --- L.P. Smith (1925) *"Words and Idioms"* {% cite smithWordsIdiomsStudies1925 %}

> Control, control for who? for what?<br>I'm no robot, they can get fucked.
>
> --- Black Flag (1981) *"No More"*

Is it still possible to imagine a different world than the one the information conglomerates have planned for us? Can we imagine a properly *human* information infrastructure?

We can start by identifying the harms of the world as it exists to understand why a new world is needed, as I have attempted some small part of in this piece. Harm, in this case, is not some speculative future of superintelligent sentient AI, but elaboration of ongoing harms of the surveillance and platform economies. 

Building a better informational world is not a matter of choosing a different set of technologies --- I argue that in this case some of the masters tools can help us rebuild his house. At the same time we can't overcorrect in our focus on social problems and dismiss technology as a strategy, a tool, and a manifestation of values, belief, and labor. We must have an answer to the well meaning liberal that mistakes the dynamics of surveillance capitalism or their role in it: that understands that these knowledge graphs are not truly universal, that the LLMs are not sentient, but embraces their logic because they're so *useful.* We have to understand why simply building open source LLMs or nonprofit linked data platforms is not a liberatory strategy. We have to appreciate how the unmet needs of information organization are caused by the very systems that claim to meet them.

At the same time, we can't dismiss those needs. How could we possibly tell someone with vision impairments not to use "AI" tools for summarizing images, or someone with motor or speech impairments not to use LLMs as a communication aid? It is true that making better use of biomedical data could lead to better treatments. Indecipherable government bureaucracy due to ancient data infrastructure is an informational injustice. So simple abstinence or resistance to universalizing knowledge graphs and LLMs is also not an effective strategy, especially if our alternative is an embrace of the same cloud platform systems whose logic spawned them. 

The constant partial satisfaction and construction of new needs, *the hollow middle* at the center of every cloud platform, is a powerful opening. The structure of contemporary platforms always pose a fundamental lack[^platformstudies]:  
- platforms create enough of their own problems
- some of the arrangements of the cloud platform world are ridiculous when said plainly. Why on earth is it possible for a medical system to volunteer my medical information without me knowing or . Why is the alternative for me to "grant permission" to access something that they are still the owners of --- why is that even *possible* in the first place? 

We also need a change in *belief.* We need to unlearn what we have been taught to want, what we believe information technologies should do, and how they are supposed to work. We need to rethink our role in information technology, to move beyond the learned helplessness of the platform consumer and the petty tyranny of the platform operator. We need to reorganize our expectations of agency, beyond the division of labor that gives the power of final say over informational systems in the hands of a cadre of experts that the rest of us just make the best of. We don't have time to argue about whether we *can* build a better world[^crimethinc], to list all the many ways we are hemmed in by infrastructure and incentives, or to wait for another powerful entity with decidedly divergent interests like a government to save us --- we need to believe we too can be powerful.

An attempt to define another "Correct" counter-belief system would be missing the point, but we can't ignore the importance of naming and articulating belief in opening the possibility for and aligning action[^crimethinc2]. Our old belief systems are getting musty.
**"Openness" has failed as a liberatory strategy.** All we make and take and offer up to each other freely is stolen ten times over by those who have much grander visions of enclosure. Without a strategy to resist co-option, our openness puts tools in the hands of the powerful. 





---

- Maybe good things are bad
	- Maybe we shouldn't want to have the seamless information world where everything can connect to everything and some information executive can come by and scoop it all up
	- Maybe having utterly seamless interfaces is not the most important part of computing - we have lost the ethical core of what 
	- Openness has failed!
	- nothing is inevitable in this world!
- The hollow middle
	- Why are we constantly bouncing around to a dozen different platforms to fill different needs, or else having to submit to comprehensive surveillance to do the basic actions of digital life
- Self-posed problems
	- you only need to automatically parse the web if you imagine yourself as providing a service that depends on having consumed all of the web!

---

**We** are the principle value of vulgar linked data. We have no dreams of world domination nor do we aspire to always make sense.

---

- transition to next section
	- the hollow middle: these things don't even *work* anyway {% cite broussardArtificialUnintelligenceHow2018 %}
		- always limited to *only exactly what the developers could imagine you wanting to do* - why should we *have to* always have our digital reality defined by someone else's ideology


vulgar LD is when we own it, rather than merely annotate things to be owned by google. what is the point where the owner of the graph can just say... no?

Stuff we draw from:
- feminist standpoint epistem. (cite data feminism and relationality lit!) {% cite mcquillanResistingAIAntifascist2022 %}
> Instead of seeing AI as an outside apparatus that takes in data about the world and spits out useful representations, we can see it as immersed in the process of shaping what things, including us, actually become. {% cite mcquillanResistingAIAntifascist2022 %}

Scraps: 

**Critically: Openness has failed us as an alternative** - it has been deeply coopted already!

- Search engine web was not inevitable either: {% cite intronaShapingWebWhy2000 %}
- as we saw with search! surveillance (in extreme part lmao) is encouraged by convenience - to make robots be maximally responsive and accurate in their responses to us, they need to fill in some missing context somewhere. surveillance is just an extremely valuable signal there. 
- open source and openness is not the alternative! FOSS can't compete with the KG part and is just a reflection of the same kind of ideology that drives the rest of the harms anyway. we need to hink of not only different tools but a fundamentally different ethos than the cloud service model. 
	- also this is why open platforms also don't work

- the poltics of ontologies are neatly illustrated by the fact that "a woman is a woman" means precisely the opposite thing w.r.t trans woman to transmisics as compared to normal people.

Why on *earth* would we want our insurance provider to be able to adjust their premiums based on our private medical information, even if it is "de-identified"

The problem of belief: what should these things do? present us instantly with results? or should they be part of a messy dialectic of information where the graph itself is the outcome? The cloud orthodoxy suggests the former!

- YOU ONLY NEED TO DO THIS SCALE OF AUTOMATED EXTRACTION IF YOU PRESUPPOSE A UNIVERSE OF A FEW MASSIVE PLATFORMS OWNING EVERYTHING IN THE FIRST PLACE re: amazon product graph example in {% cite chaudhriKnowledgeGraphsIntroduction2022 %}

- cognitive expectations of search
	- 2002 RDF Core WG talking about whether we want things to work like google or not... {% cite sticklerReMonotonicityWas2002 %} - https://lists.w3.org/Archives/Public/w3c-rdfcore-wg/2002Sep/0276.html

*Why does it always feel like there is a hollow middle?* - eg. I can't even index across the different projects in the translator. I feel like I always need to subscribe to some additional platform or service, rather than making cumulative progress on a single thing. Always tossed around in an endless sea. This is a reflection of platforms necessarily generating the fundamental lack which they can exploit - typically informational organization. Why do our public information infrastructures which shoudln't be subject to the same profit-based constraints as cloud platforms, also feel this way? Because the cloud paradigm is specifically designed to favor a particular paradigm of computing.